import csv
import os

import cv2
import numpy as np
import torch
from tqdm import tqdm

from scripts.goggle_classifier import get_model
from scripts.constants import VIDEO_EXT
from scripts.utils import check_rotation, correct_rotation, bbox_iou
from src.jetson.face_detector import FaceDetector
from src.jetson.classifier import Classifier


class Evaluator():
    def __init__(self, cuda, detector, detector_type, classifier, input_directory, rate,
                 comparison_dets_file, self_dets_file):
        """
        Evaluates face detection and goggle classification performance.
        Goggle Classification accuracy is given by average class accuracy and 
        accuracy for each individual video.
        Face detection accuracy is given by precision and recall values.

        @param cuda: A bool value that specifies if cuda shall be used
        @param detector: A string path to a .pth weights file for a face detection model
        @param detector_type: One of 'blazeface', 'ssd', 'retinaface'.
        @param classifier: A string path to a .pth weights file for a goggle classification model
        @param input_directory: Directory containing test videos to run Evaluator on
        @param rate: Run detection and classification on every 1/rate frames
        @param comparison_dets_file: CSV generated by annotator.py containing detection results
         of another detection model (to be compared)
        @param self_dets_file: CSV generated by this class containing detections by self.detector
        """
        if cuda and torch.cuda.is_available():
            torch.set_default_tensor_type('torch.cuda.FloatTensor')
            self.device = torch.device('cuda:0')
        else:
            torch.set_default_tensor_type('torch.FloatTensor')
            self.device = torch.device('cpu')

        self.detector = FaceDetector(detector=detector, detector_type=detector_type,
                                     cuda=cuda and torch.cuda.is_available(), set_default_dev=True)

        weights = torch.load(classifier, map_location=self.device)
        if isinstance(weights, dict):
            # if the .pth is just a state_dict, we need to
            # load the model from goggle_classifier.py
            model = get_model()
            model.load_state_dict(weights)
            weights = model

        self.classifier = Classifier(weights, cuda)
        self.video_filenames = self.get_video_files(input_directory)
        self.results = {'Goggles':
                            {'average_class_accuracy': 0.0,
                             'number_of_videos': 0,
                             'individual_video_results': {}
                             },
                        'Glasses':
                            {'average_class_accuracy': 0.0,
                             'number_of_videos': 0,
                             'individual_video_results': {}
                             },
                        'Neither':
                            {'average_class_accuracy': 0.0,
                             'number_of_videos': 0,
                             'individual_video_results': {}
                             }
                        }
        self.class_label = ''
        self.condition = ''
        self.cap = ''
        self.video = ''
        self.video_len = 0
        self.rate = rate
        self.comparison_dets_file = comparison_dets_file
        self.evaluate()
        self.self_dets_file = self_dets_file

        if os.path.exists(self.self_dets_file):
            os.remove(self.self_dets_file)

    def evaluate(self):
        """
        Evaluates (classification and detection) every video file in the input directory
        containing test videos and stores results in self.results.
        To understand the format of the self.results dict, check the constructor
        """
        total_videos_processed = 0
        for video_file in self.video_filenames:
            self.video = video_file
            print(f"Processing {self.video} ..., video {total_videos_processed}/{len(self.video_filenames)}")

            self.class_label = self.get_class_label()
            self.condition = self.get_condition()
            self.cap = cv2.VideoCapture(self.video)

            if self.cap.isOpened():
                self.evaluate_classifications()  # Also contains boxes
                total_videos_processed += 1
                print(f"{self.video} : Done")
            else:
                print(f"Unable to open video {self.video}")
                continue

        self.calculate_average_class_accuracy()

        if self.comparison_dets_file is not None:
            self.evaluate_detections(self.comparison_dets_file, self.self_dets_file)

        print(f"\n {total_videos_processed} videos processed!")

    def evaluate_classifications(self):
        """
        Run classification on one video, save classification results
        """
        inferences = self.infer()
        if sum(inferences.values()) == 0:
            percentage_of_correct_predictions = 0
        else:
            percentage_of_correct_predictions = inferences[self.class_label] / sum(inferences.values())

        self.record_results((percentage_of_correct_predictions, inferences, sum(inferences.values())))

    def evaluate_detections(self, ground_truth_detections_file, predicted_detections_file):
        """
        Calculates the recall and precision of face detection for a video.
        A "correct" detection is defined by 0.5 IoU or greater with the bounding box of the comparison detections.

        @param ground_truth_detections_file: file containing detections to be compared (created by annotator.py)
        @param predicted_detections_file: file containing detections by self.detector
        """
        ground_truth_detections = []
        predicted_detections = []
        with open(ground_truth_detections_file, newline='') as detect_file:
            reader = csv.reader(detect_file)
            for row in reader:
                ground_truth_detections.append(row)

        with open(predicted_detections_file, newline='') as prediction_file:
            reader = csv.reader(prediction_file)
            for row in reader:
                predicted_detections.append(row)

        true_pos = 0
        false_pos = 0

        for d in predicted_detections:
            # only look at frames where a face was detected
            if len(d) > 2:
                ground_truth_bboxes = None
                pred_bboxes = d[2:6]

                # get matching frame detection from the ground_truth
                for detection in ground_truth_detections:
                    if detection[0] == d[0] and detection[1] == d[1]:
                        if len(detection) > 2:
                            # if the ground truth also detected a face in this frame
                            ground_truth_bboxes = detection[2:6]
                        break

                if ground_truth_bboxes is not None:
                    # 0.5 IoU is commonly used to compare bounding boxes
                    if bbox_iou(pred_bboxes, ground_truth_bboxes) > 0.5:
                        true_pos += 1
                    else:
                        false_pos += 1
                else:
                    # ground truth did not detect a face, but the prediction did
                    false_pos += 1

        total_ground_truths = len(ground_truth_detections)
        print("Total ground truths: ", total_ground_truths)

        recall = true_pos / float(total_ground_truths)
        # avoid divide by zero in case the first detection matches a difficult ground truth
        precision = true_pos / np.maximum(true_pos + false_pos, np.finfo(np.float64).eps)

        print("Precision: ", precision)
        print("Recall: ", recall)
        return precision, recall

    def infer(self):
        """
        Performs inference on a video using the face detection
        and goggle classification models.
        Also saves the face detections if they're going to be compared later

        @return inference_dict: the number of inferences for each class
        """
        detections = []
        preds = []
        inference_dict = {"Goggles": 0, "Glasses": 0, "Neither": 0}

        rotate_code = check_rotation(self.video)
        self.video_len = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

        for frame_num in tqdm(range(self.video_len)):
            ret, img = self.cap.read()
            if frame_num % self.rate == 0 and img is not None:
                if rotate_code is not None:
                    correct_rotation(img, rotate_code)
                boxes = self.detector.detect(img)  # Also contains confidence
                detection = [self.video, frame_num]
                for box in boxes:
                    x1 = max(0, box[0])
                    y1 = max(0, box[1])
                    x2 = min(img.shape[1], box[2])
                    y2 = min(img.shape[0], box[3])
                    conf = box[4]
                    face = img[int(y1):int(y2), int(x1):int(x2), :]
                    label = self.classifier.classifyFace(face)
                    preds.append(label.item())
                    detection.extend([x1, y1, x2, y2, conf])
                detections.append(detection)

        inference_dict["Glasses"] += preds.count(0)
        inference_dict["Goggles"] += preds.count(1)
        inference_dict["Neither"] += preds.count(2)

        # save the detections for comparison later
        if self.comparison_dets_file is not None:
            with open(self.self_dets_file, "a") as f:
                writer = csv.writer(f)
                writer.writerows(detections)

        return inference_dict

    def calculate_average_class_accuracy(self):
        """
        Calculates the average class accuracy for each class and stores it in self.results
        """
        for class_label in self.results:
            if self.results[class_label]['number_of_videos'] > 0:
                self.results[class_label]['average_class_accuracy'] = self.results[class_label][
                                                                          'average_class_accuracy'] / \
                                                                      self.results[class_label]['number_of_videos']

    def record_results(self, result):
        """
        Records results of one video in the self.results dict.
        All of this information is necessary for getting detailed face detection results
        and creating classifier confusion matrices.

        @param result(List) - contains the classification accuracy,
        number of predictions for each label, number of detections (see evaluate_classifications)
        """
        self.results[self.class_label]['number_of_videos'] += 1
        # average_class_accuracy is a running sum which gets divided by the number of videos after evaluating all videos
        # (see calculate_average_class_accuracy)
        self.results[self.class_label]['average_class_accuracy'] += result[0]
        self.results[self.class_label]['individual_video_results'][self.video] = {}
        self.results[self.class_label]['individual_video_results'][self.video]["accuracy"] = result[0]
        self.results[self.class_label]['individual_video_results'][self.video]["glasses"] = result[1]['Glasses']
        self.results[self.class_label]['individual_video_results'][self.video]["goggles"] = result[1]['Goggles']
        self.results[self.class_label]['individual_video_results'][self.video]["neither"] = result[1]['Neither']
        self.results[self.class_label]['individual_video_results'][self.video]["num_detections"] = result[2]
        self.results[self.class_label]['individual_video_results'][self.video]["num_frames"] = self.video_len
        self.results[self.class_label]['individual_video_results'][self.video]["condition"] = self.condition

    def get_class_label(self):
        """
        Get class label [Goggles / Glasses / Neither] that the image belongs to
        """
        if '/Goggles/' in self.video or '/goggles/' in self.video:
            class_label = 'Goggles'
        elif '/Glasses/' in self.video or '/glasses/' in self.video:
            class_label = 'Glasses'
        else:
            class_label = 'Neither'

        return class_label

    def get_condition(self):
        """
        Get condition [Ideal, low_lighting etc. ] that the image belongs to
        """
        return self.video.split('/')[-2]

    def get_video_files(self, input_directory: str):
        """
        Gets all the video files in the input directory
        """
        filenames = []
        for dirName, subdirList, fileList in os.walk(input_directory):
            for filename in fileList:
                ext = '.' + filename.split('.')[-1]
                if ext in VIDEO_EXT:
                    filenames.append(dirName + '/' + filename)

        return filenames

    def get_evaluator_results(self):
        """
        Returns the dict containing all the test results (self.results)
        """
        return self.results
